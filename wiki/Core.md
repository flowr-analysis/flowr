_This document was generated from '[src/documentation/print-core-wiki.ts](https://github.com/flowr-analysis/flowr/tree/main//src/documentation/print-core-wiki.ts)' on 2025-03-21, 07:45:49 UTC presenting an overview of flowR's core (v2.2.12, using R v4.4.3). Please do not edit this file/wiki page directly._

This wiki page provides an overview of the inner workings of _flowR_.
It is mostly intended for developers that want to extend the capabilities of _flowR_
and assumes knowledge of [TypeScript](https://www.typescriptlang.org/) and [R](https://www.r-project.org/).
If you think parts of the wiki are missing, wrong, or outdated, please do not hesitate to [open a new issue](https://github.com/flowr-analysis/flowr/issues/new/choose)!
In case you are new and want to develop for flowR, please check out the relevant [Setup](https://github.com/flowr-analysis/flowr/wiki/Setup#-developing-for-flowr) wiki page
and the [Contributing Guidelines](https://github.com/flowr-analysis/flowr/tree/main//.github/CONTRIBUTING.md).


> [!NOTE]
> 
> Essentially every step we explain here can be explored directly from flowR's REPL in an interactive fashion (see the [Interface](https://github.com/flowr-analysis/flowr/wiki/Interface#using-the-repl) wiki page).
> We recommend to use commands like <span title="Description (Repl Command): Prints ASCII Art of the parsed, unmodified AST, start with 'file://' to indicate a file (aliases: :p)">`:parse`</span> or <span title="Description (Repl Command, starred version): Returns the URL to mermaid.live; Base Command: Get mermaid code for the dataflow graph of R code, start with 'file://' to indicate a file (aliases: :d*, :df*)">`:dataflow*`</span> to explore the output of flowR using your own samples.
> As a quickstart you may use:
> 
> 
> 
> ```shell
> $ docker run -it --rm eagleoutice/flowr # or npm run flowr 
> flowR repl using flowR v2.2.12, R v4.4.3 (r-shell engine)
> R> :parse "x <- 1; print(x)"
> ```
> 
> <details>
> <summary style='color:gray'>Output</summary>
> 
> 
> ```text
> exprlist
> ├ expr
> │ ├ expr
> │ │ ╰ SYMBOL "x" (1:1)
> │ ├ LEFT_ASSIGN "<-" (1:3─4)
> │ ╰ expr
> │   ╰ NUM_CONST "1" (1:6)
> ├ ; ";" (1:7)
> ╰ expr
>   ├ expr
>   │ ╰ SYMBOL_FUNCTION_CALL "print" (1:9─13)
>   ├ ( "(" (1:14)
>   ├ expr
>   │ ╰ SYMBOL "x" (1:15)
>   ╰ ) ")" (1:16)
> ```
> 
> 
> Retrieves the AST from the [<code><span title="The RShell represents an interactive session with the R interpreter. You can configure it by RShellOptions .  At the moment we are using a live R session (and not networking etc.) to communicate with R easily, which allows us to install packages etc. However, this might and probably will change in the future (leaving this as a legacy mode :D)">RShell</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/shell.ts#L140).
> 
> </details>
> 
> 
> 	
> If you are brave (or desperate) enough, you can also try to use the <span title="Description (Command Line Argument): Run with verbose logging (will be passed to the corresponding script)">`--verbose`</span> option to be dumped with information about flowR's internals (please, never use this for benchmarking).
> See the [Getting flowR to Talk](#getting-flowr-to-talk) section below for more information.
> 

	
* [Pipelines and their Execution](#pipelines-and-their-execution)
* [How flowR Produces Dataflow Graphs](#how-flowr-produces-dataflow-graphs)
  * [Overview](#overview)
  * [Parsing](#parsing)
  * [Normalization](#normalization)
  * [Dataflow Graph Generation](#dataflow-graph-generation)
* [Beyond the Dataflow Graph](#beyond-the-dataflow-graph)
  * [Static Backward Slicing](#static-backward-slicing)
* [Getting flowR to Talk](#getting-flowr-to-talk)
	
## Pipelines and their Execution

At the core of every analysis by flowR is the [<code><span title="The pipeline executor allows to execute arbitrary pipelines in a step-by-step fashion. If you are not yet in the possession of a pipeline , you can use the createPipeline function to create one for yourself, based on the steps that you want to execute.  Those steps are split into two phases or 'stages' (which is the name that we will use in the following), represented by the PipelineStepStage type...">PipelineExecutor</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/pipeline-executor.ts#L98) class which takes a sequence of analysis steps (in the form of a [<code><span title="A pipeline is a collection of steps that are executed in a certain order . It is to be created createPipeline .  If you want to get the type of all steps in the pipeline (given they are created canonically using const step names), refer to PipelineStepNames .">Pipeline</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/pipeline/pipeline.ts#L11)) and executes it
on a given input. In general, these pipeline steps are analysis agnostic and may use arbitrary input and ordering. However, two important and predefined pipelines, 
the [<code><span title="The default pipeline for working with flowR, including the dataflow step. See the DEFAULT_NORMALIZE_PIPELINE for the pipeline without the dataflow step and the DEFAULT_SLICE_AND_RECONSTRUCT_PIPELINE for the pipeline with slicing and reconstructing steps">DEFAULT_DATAFLOW_PIPELINE</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/pipeline/default-pipelines.ts#L30) and the [<code>TREE_SITTER_DATAFLOW_PIPELINE</code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/pipeline/default-pipelines.ts#L31) adequately cover the most common analysis steps 
(differentiated only by the [Engine](https://github.com/flowr-analysis/flowr/wiki/Engines) used).


> [!TIP]
> 
> 	You can hover over most links within these wiki pages to get access to the tsdoc comment of the respective element. 
> 	The links should direct you to the up-to-date implementation.
> 

	
Using the [`tree-sitter` engine](https://github.com/flowr-analysis/flowr/wiki/Engines) you can request a dataflow analysis of a sample piece of R code like the following:


```typescript
const executor = new PipelineExecutor(TREE_SITTER_DATAFLOW_PIPELINE, {
	parser:  new TreeSitterExecutor(),
	request: requestFromInput('x <- 1; y <- x; print(y);')
});
const result = await executor.allRemainingSteps();
```


This is, roughly, what the [<code><span title="Obtain the dataflow graph using a known parser (such as the RShell or TreeSitterExecutor ).">replGetDataflow</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/cli/repl/commands/repl-dataflow.ts#L11) function does for the <span title="Description (Repl Command): Get mermaid code for the dataflow graph of R code, start with 'file://' to indicate a file (aliases: :d, :df)">`:dataflow`</span> REPL command when using the [`tree-sitter` engine](https://github.com/flowr-analysis/flowr/wiki/Engines).
We create a new [<code><span title="The pipeline executor allows to execute arbitrary pipelines in a step-by-step fashion. If you are not yet in the possession of a pipeline , you can use the createPipeline function to create one for yourself, based on the steps that you want to execute.  Those steps are split into two phases or 'stages' (which is the name that we will use in the following), represented by the PipelineStepStage type...">PipelineExecutor</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/pipeline-executor.ts#L98) with the [<code>TREE_SITTER_DATAFLOW_PIPELINE</code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/pipeline/default-pipelines.ts#L31) and then use [<code>allRemainingSteps</code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/pipeline-executor.ts#L246) 
to cause the execution of all contained steps (in general, pipelines can be executed step-by-step, but this is usually not required if you just want the result).
[<code>requestFromInput</code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/retriever.ts#L52) is merely a convenience function to create a request object from a code string.

In general, however, most flowR-internal functions which are tasked with generating dataflow prefer the use of [<code>createDataflowPipeline</code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/pipeline/default-pipelines.ts#L93) as this function
automatically selects the correct pipeline based on the engine used.

### Understanding Pipeline Steps

Everything that complies to the [<code><span title="Defines what is to be known of a single step in a pipeline. It wraps around a single processor function, providing additional information. Steps will be executed synchronously, in-sequence, based on their dependencies .">IPipelineStep</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/pipeline-step.ts#L70) interface can be used as a step in a pipeline, with the most important definition being the
`processor` function, which refers to the actual work performed by the step.
For example, the [<code>STATIC_DATAFLOW</code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/all/core/20-dataflow.ts#L34) step ultimately relies on the [<code><span title="This is the main function to produce the dataflow graph from a given request and normalized AST. Note, that this requires knowledge of the active parser in case the dataflow analysis uncovers other files that have to be parsed and integrated into the analysis (e.g., in the event of a source call). For the actual, canonical fold entry point, see processDataflowFor .">produceDataFlowGraph</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/extractor.ts#L94) function to create a [dataflow graph](https://github.com/flowr-analysis/flowr/wiki/Dataflow-Graph) 
using the [normalized AST](https://github.com/flowr-analysis/flowr/wiki/Normalized-AST) of the program.

### Shape of a Pipeline Step

Using code, you can provide an arbitrary pipeline step to the executor, as long as it implements the [<code><span title="Defines what is to be known of a single step in a pipeline. It wraps around a single processor function, providing additional information. Steps will be executed synchronously, in-sequence, based on their dependencies .">IPipelineStep</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/pipeline-step.ts#L70) interface:

 * **[IPipelineStep](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/pipeline-step.ts#L70)**   
   Defines what is to be known of a single step in a pipeline.
   It wraps around a single
   <code>processor</code>
   function, providing additional information.
   Steps will be executed synchronously, in-sequence, based on their
   <code>dependencies</code>
   .
   <details><summary style="color:gray">Defined at <a href="https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/pipeline-step.ts#L70">./src/core/steps/pipeline-step.ts#L70</a></summary>
   
   
   ```ts
   /**
    * Defines what is to be known of a single step in a pipeline.
    * It wraps around a single {@link IPipelineStep#processor|processor} function, providing additional information.
    * Steps will be executed synchronously, in-sequence, based on their {@link IPipelineStep#dependencies|dependencies}.
    */
   export interface IPipelineStep<
       Name extends PipelineStepName = PipelineStepName,
       // eslint-disable-next-line -- by default, we assume nothing about the function shape
       Fn extends StepProcessingFunction = (...args: any[]) => any,
   > extends MergeableRecord, IPipelineStepOrder<Name> {
       /** Human-readable name of this step */
       readonly humanReadableName: string
       /** Human-readable description of this step */
       readonly description:       string
       /** The main processor that essentially performs the logic of this step */
       readonly processor:         (...input: Parameters<Fn>) => ReturnType<Fn>
       /** How to visualize the results of the respective step to the user? */
       readonly printer: {
           [K in StepOutputFormat]?: IPipelineStepPrinter<Fn, K, never[]>
       } & {
           // we always want to have an internal printer
           [StepOutputFormat.Internal]: InternalStepPrinter<Fn>
       }
       /**
        * Input configuration required to perform the respective steps.
        * Required inputs of dependencies do not have to, but can be repeated.
        * <p>
        * Use the pattern `undefined as unknown as T` to indicate that the value is required but not provided.
        */
       readonly requiredInput: object
   }
   ```
   
   
   </details>
   

Every step may specify required inputs, ways of visualizing the output, and its dependencies using the [<code><span title="Contains the data to specify the order of steps in a pipeline.">IPipelineStepOrder</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/pipeline-step.ts#L39) interface.
As the types may seem to be somewhat confusing or over-complicated, we recommend you to look at some existing steps, like 
the [<code>PARSE_WITH_R_SHELL_STEP</code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/all/core/00-parse.ts#L10) or the [<code>STATIC_DATAFLOW</code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/all/core/20-dataflow.ts#L34) step.
The pipeline executor should do a good job of scheduling these steps (usually using a topological sort), and inferring the required inputs in the type system (have a look at the [<code><span title="Creates a pipeline from a given collection of steps . To be valid, the collection of steps must satisfy the following set of constraints (which should be logical, when you consider what a pipeline should achieve):  0) the collection of steps is not empty 1) all names of steps are unique for the given pipeline 2) all dependencies of all steps exist 3) there are no cycles in the dependency graph 4) ...">createPipeline</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/pipeline/pipeline.ts#L144) function if you want to know more).


> [!NOTE]
> 
> Under the hood there is a step-subtype called a decoration. Such a step can be added to a pipeline to decorate the output of another one (e.g., making it more precise, re-adding debug info, ...).
> To mark a step as a decoration, you can use the `decorates` field in the [<code><span title="Contains the data to specify the order of steps in a pipeline.">IPipelineStepOrder</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/pipeline-step.ts#L39) interface.
> However, as such steps are currently not relevant for any of flowR's core analyses we will not go into detail here. It suffices to know how "real" steps work.
> 

	
## How flowR Produces Dataflow Graphs

This section focuses on the generation of a [dataflow graph](https://github.com/flowr-analysis/flowr/wiki/Dataflow-Graph) from a given R program, using the [RShell Engine](https://github.com/flowr-analysis/flowr/wiki/Engines) and hence the 
[<code><span title="The default pipeline for working with flowR, including the dataflow step. See the DEFAULT_NORMALIZE_PIPELINE for the pipeline without the dataflow step and the DEFAULT_SLICE_AND_RECONSTRUCT_PIPELINE for the pipeline with slicing and reconstructing steps">DEFAULT_DATAFLOW_PIPELINE</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/pipeline/default-pipelines.ts#L30). The [`tree-sitter` engine](https://github.com/flowr-analysis/flowr/wiki/Engines) uses the [<code>TREE_SITTER_DATAFLOW_PIPELINE</code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/pipeline/default-pipelines.ts#L31)), 
which replaces the parser with the integrated tree-sitter parser and hence uses a slightly adapted normalization step to produce a similar [normalized AST](https://github.com/flowr-analysis/flowr/wiki/Normalized-AST).
The [dataflow graph](https://github.com/flowr-analysis/flowr/wiki/Dataflow-Graph) should be the same for both engines (although [`tree-sitter`](https://github.com/flowr-analysis/flowr/wiki/Engines) is faster and may be able to parse more files).

### Overview

Let's have a look at the definition of the pipeline:

 * [DEFAULT_DATAFLOW_PIPELINE](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/pipeline/default-pipelines.ts#L30)   
   The default pipeline for working with flowR, including the dataflow step.
   See the
   <code>DEFAULT_NORMALIZE_PIPELINE</code>
   for the pipeline without the dataflow step
   and the
   <code>DEFAULT_SLICE_AND_RECONSTRUCT_PIPELINE</code>
   for the pipeline with slicing and reconstructing steps
   <details><summary style="color:gray">Defined at <a href="https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/pipeline/default-pipelines.ts#L30">./src/core/steps/pipeline/default-pipelines.ts#L30</a></summary>
   
   
   ```ts
   DEFAULT_DATAFLOW_PIPELINE = createPipeline(PARSE_WITH_R_SHELL_STEP, NORMALIZE, STATIC_DATAFLOW)
   ```
   
   
   </details>
   

We can see that it relies on three steps:

1. **[PARSE_WITH_R_SHELL_STEP](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/all/core/00-parse.ts#L10)** ([parsing](#parsing)): Uses the [<code><span title="The RShell represents an interactive session with the R interpreter. You can configure it by RShellOptions .  At the moment we are using a live R session (and not networking etc.) to communicate with R easily, which allows us to install packages etc. However, this might and probably will change in the future (leaving this as a legacy mode :D)">RShell</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/shell.ts#L140) to parse the input program.\
   _Its main function linked as the processor is the [<span title="Takes an input program and parses it using the given parser.">parseRequests</span>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/parser.ts#L52) function._
2. **[NORMALIZE](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/all/core/10-normalize.ts#L37)** ([normalization](#normalization)):  Normalizes the AST produced by the parser (to create a [normalized AST](https://github.com/flowr-analysis/flowr/wiki/Normalized-AST)).\
   _Its main function linked as the processor is the [<span title="the normalized AST produced by the 'normalization' step, including its parent decoration">normalize</span>](https://github.com/flowr-analysis/flowr/tree/main//src/benchmark/slicer.ts#L65) function._
3. **[STATIC_DATAFLOW](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/all/core/20-dataflow.ts#L34)** ([dataflow](#dataflow-graph-generation)): Produces the actual [dataflow graph](https://github.com/flowr-analysis/flowr/wiki/Dataflow-Graph) from the normalized AST.\
   _Its main function linked as the processor is the [<span title="This is the main function to produce the dataflow graph from a given request and normalized AST. Note, that this requires knowledge of the active parser in case the dataflow analysis uncovers other files that have to be parsed and integrated into the analysis (e.g., in the event of a source call). For the actual, canonical fold entry point, see processDataflowFor .">produceDataFlowGraph</span>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/extractor.ts#L94) function._

To explore these steps, let's use the REPL with the (very simple and contrived) R code: `x <- 1; print(x)`.



```shell
$ docker run -it --rm eagleoutice/flowr # or npm run flowr 
flowR repl using flowR v2.2.12, R v4.4.3 (r-shell engine)
R> :parse "x <- 1; print(x)"
```

<details>
<summary style='color:gray'>Output</summary>


```text
exprlist
├ expr
│ ├ expr
│ │ ╰ SYMBOL "x" (1:1)
│ ├ LEFT_ASSIGN "<-" (1:3─4)
│ ╰ expr
│   ╰ NUM_CONST "1" (1:6)
├ ; ";" (1:7)
╰ expr
  ├ expr
  │ ╰ SYMBOL_FUNCTION_CALL "print" (1:9─13)
  ├ ( "(" (1:14)
  ├ expr
  │ ╰ SYMBOL "x" (1:15)
  ╰ ) ")" (1:16)
```


This shows the ASCII-Art representation of the parse-tree of the R code `x <- 1; print(x)`, as it is provided by the [<code><span title="The RShell represents an interactive session with the R interpreter. You can configure it by RShellOptions .  At the moment we are using a live R session (and not networking etc.) to communicate with R easily, which allows us to install packages etc. However, this might and probably will change in the future (leaving this as a legacy mode :D)">RShell</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/shell.ts#L140). See the [<code><span title="Command(s) to be issued at the start of each shell">initCommand</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/init.ts#L6) function for more information on how we request a parse.

</details>



```shell
R> :normalize* "x <- 1; print(x)"
```

<details>
<summary style='color:gray'>Output</summary>


```text
https://mermaid.live/view#base64:eyJjb2RlIjoiZmxvd2NoYXJ0IFREXG4gICAgbjcoW1wiUkV4cHJlc3Npb25MaXN0ICg3KVxuIFwiXSlcbiAgICBuMihbXCJSQmluYXJ5T3AgKDIpXG4jNjA7IzQ1O1wiXSlcbiAgICBuNyAtLT58XCJleHByLWxpc3QtY2hpbGQtMFwifCBuMlxuICAgIG4wKFtcIlJTeW1ib2wgKDApXG54XCJdKVxuICAgIG4yIC0tPnxcImJpbm9wLWxoc1wifCBuMFxuICAgIG4xKFtcIlJOdW1iZXIgKDEpXG4xXCJdKVxuICAgIG4yIC0tPnxcImJpbm9wLXJoc1wifCBuMVxuICAgIG42KFtcIlJGdW5jdGlvbkNhbGwgKDYpXG5wcmludFwiXSlcbiAgICBuNyAtLT58XCJleHByLWxpc3QtY2hpbGQtMVwifCBuNlxuICAgIG4zKFtcIlJTeW1ib2wgKDMpXG5wcmludFwiXSlcbiAgICBuNiAtLT58XCJjYWxsLW5hbWVcInwgbjNcbiAgICBuNShbXCJSQXJndW1lbnQgKDUpXG54XCJdKVxuICAgIG42IC0tPnxcImNhbGwtYXJndW1lbnQtMVwifCBuNVxuICAgIG40KFtcIlJTeW1ib2wgKDQpXG54XCJdKVxuICAgIG41IC0tPnxcImFyZy12YWx1ZVwifCBuNFxuIiwibWVybWFpZCI6eyJhdXRvU3luYyI6dHJ1ZX19
```


Following the link output should show the following:



```mermaid
flowchart TD
    n7(["RExpressionList (7)
 "])
    n2(["RBinaryOp (2)
#60;#45;"])
    n7 -->|"expr-list-child-0"| n2
    n0(["RSymbol (0)
x"])
    n2 -->|"binop-lhs"| n0
    n1(["RNumber (1)
1"])
    n2 -->|"binop-rhs"| n1
    n6(["RFunctionCall (6)
print"])
    n7 -->|"expr-list-child-1"| n6
    n3(["RSymbol (3)
print"])
    n6 -->|"call-name"| n3
    n5(["RArgument (5)
x"])
    n6 -->|"call-argument-1"| n5
    n4(["RSymbol (4)
x"])
    n5 -->|"arg-value"| n4

```
	
(The analysis required _4.64 ms_ (including parsing with the [r-shell](https://github.com/flowr-analysis/flowr/wiki/Engines) engine) within the generation environment.)



</details>



```shell
R> :dataflow* "x <- 1; print(x)"
```

<details>
<summary style='color:gray'>Output</summary>


```text
https://mermaid.live/view#base64:eyJjb2RlIjoiZmxvd2NoYXJ0IEJUXG4gICAgMXt7XCJgIzkxO1JOdW1iZXIjOTM7IDFcbiAgICAgICgxKVxuICAgICAgKjEuNipgXCJ9fVxuICAgIDBbXCJgIzkxO1JTeW1ib2wjOTM7IHhcbiAgICAgICgwKVxuICAgICAgKjEuMSpgXCJdXG4gICAgMltbXCJgIzkxO1JCaW5hcnlPcCM5MzsgIzYwOyM0NTtcbiAgICAgICgyKVxuICAgICAgKjEuMS02KlxuICAgICgwLCAxKWBcIl1dXG4gICAgNChbXCJgIzkxO1JTeW1ib2wjOTM7IHhcbiAgICAgICg0KVxuICAgICAgKjEuMTUqYFwiXSlcbiAgICA2W1tcImAjOTE7UkZ1bmN0aW9uQ2FsbCM5MzsgcHJpbnRcbiAgICAgICg2KVxuICAgICAgKjEuOS0xNipcbiAgICAoNClgXCJdXVxuICAgIDAgLS0+fFwiZGVmaW5lZC1ieVwifCAxXG4gICAgMCAtLT58XCJkZWZpbmVkLWJ5XCJ8IDJcbiAgICAyIC0tPnxcImFyZ3VtZW50XCJ8IDFcbiAgICAyIC0tPnxcInJldHVybnMsIGFyZ3VtZW50XCJ8IDBcbiAgICA0IC0tPnxcInJlYWRzXCJ8IDBcbiAgICA2IC0tPnxcInJlYWRzLCByZXR1cm5zLCBhcmd1bWVudFwifCA0IiwibWVybWFpZCI6eyJhdXRvU3luYyI6dHJ1ZX19
```


Following the link output should show the following:




```mermaid
flowchart LR
    1{{"`#91;RNumber#93; 1
      (1)
      *1.6*`"}}
    0["`#91;RSymbol#93; x
      (0)
      *1.1*`"]
    2[["`#91;RBinaryOp#93; #60;#45;
      (2)
      *1.1-6*
    (0, 1)`"]]
    4(["`#91;RSymbol#93; x
      (4)
      *1.15*`"])
    6[["`#91;RFunctionCall#93; print
      (6)
      *1.9-16*
    (4)`"]]
    0 -->|"defined-by"| 1
    0 -->|"defined-by"| 2
    2 -->|"argument"| 1
    2 -->|"returns, argument"| 0
    4 -->|"reads"| 0
    6 -->|"reads, returns, argument"| 4
```

	
(The analysis required _7.28 ms_ (including parse and normalize, using the [r-shell](https://github.com/flowr-analysis/flowr/wiki/Engines) engine) within the generation environment.)



</details>


	

> [!TIP]
> 
> 	All of these commands accept file paths as well, so you can write longer R code within a file, and then pass 
> 	the file path prefixed with `file://` (e.g., `file://test/testfiles/example.R`) to the commands.
	

Especially when you are just starting with flowR, we recommend using the REPL to explore the output of the different steps.


> [!NOTE]
> Maybe you are left with the question: What is tree-sitter doing differently? Expand the following to get more information!
> 
> 
> <details><summary style="">And what changes with tree-sitter?</summary>
> 
> 
> 
> Essentially not much (from a user perspective, it does essentially everything and all differently under the hood)! Have a look at the [Engines](https://github.com/flowr-analysis/flowr/wiki/Engines) wiki page for more information on the differences between the engines.
> Below you can see the Repl commands for the tree-sitter engine (using <span title="Description (Command Line Argument): The default engine to use for interacting with R code. If this is undefined, an arbitrary engine from the specified list will be used.">`--default-engine`</span> to set the engine to tree-sitter):
> 
> 
> 
> ```shell
> $ docker run -it --rm eagleoutice/flowr --default-engine tree-sitter # or npm run flowr -- --default-engine tree-sitter
> flowR repl using flowR v2.2.12, R grammar v14 (tree-sitter engine)
> R> :parse "x <- 1; print(x)"
> ```
> 
> <details>
> <summary style='color:gray'>Output</summary>
> 
> 
> ```text
> program
> ├ binary_operator
> │ ├ identifier "x" (1:1─2)
> │ ├ <- "<-" (1:3─5)
> │ ╰ float "1" (1:6─7)
> ╰ call
>   ├ identifier "print" (1:9─14)
>   ╰ arguments
>     ├ ( "(" (1:14─15)
>     ├ argument
>     │ ╰ identifier "x" (1:15─16)
>     ╰ ) ")" (1:16─17)
> ```
> 
> 
> This shows the ASCII-Art representation of the parse-tree of the R code `x <- 1; print(x)`, as it is provided by the [<code><span title="Synchronous and (way) faster alternative to the RShell using tree-sitter.">TreeSitterExecutor</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/tree-sitter/tree-sitter-executor.ts#L16). See the [Engines](https://github.com/flowr-analysis/flowr/wiki/Engines) wiki page for more information on the differences between the engines.
> 
> </details>
> 
> 
> 
> ```shell
> R> :normalize* "x <- 1; print(x)"
> ```
> 
> <details>
> <summary style='color:gray'>Output</summary>
> 
> 
> ```text
> https://mermaid.live/view#base64:eyJjb2RlIjoiZmxvd2NoYXJ0IFREXG4gICAgbjcoW1wiUkV4cHJlc3Npb25MaXN0ICg3KVxuIFwiXSlcbiAgICBuMihbXCJSQmluYXJ5T3AgKDIpXG4jNjA7IzQ1O1wiXSlcbiAgICBuNyAtLT58XCJleHByLWxpc3QtY2hpbGQtMFwifCBuMlxuICAgIG4wKFtcIlJTeW1ib2wgKDApXG54XCJdKVxuICAgIG4yIC0tPnxcImJpbm9wLWxoc1wifCBuMFxuICAgIG4xKFtcIlJOdW1iZXIgKDEpXG4xXCJdKVxuICAgIG4yIC0tPnxcImJpbm9wLXJoc1wifCBuMVxuICAgIG42KFtcIlJGdW5jdGlvbkNhbGwgKDYpXG5wcmludFwiXSlcbiAgICBuNyAtLT58XCJleHByLWxpc3QtY2hpbGQtMVwifCBuNlxuICAgIG4zKFtcIlJTeW1ib2wgKDMpXG5wcmludFwiXSlcbiAgICBuNiAtLT58XCJjYWxsLW5hbWVcInwgbjNcbiAgICBuNShbXCJSQXJndW1lbnQgKDUpXG54XCJdKVxuICAgIG42IC0tPnxcImNhbGwtYXJndW1lbnQtMVwifCBuNVxuICAgIG40KFtcIlJTeW1ib2wgKDQpXG54XCJdKVxuICAgIG41IC0tPnxcImFyZy12YWx1ZVwifCBuNFxuIiwibWVybWFpZCI6eyJhdXRvU3luYyI6dHJ1ZX19
> ```
> 
> 
> Following the link output should show the following:
> 
> 
> 
> ```mermaid
> flowchart TD
>     n7(["RExpressionList (7)
>  "])
>     n2(["RBinaryOp (2)
> #60;#45;"])
>     n7 -->|"expr-list-child-0"| n2
>     n0(["RSymbol (0)
> x"])
>     n2 -->|"binop-lhs"| n0
>     n1(["RNumber (1)
> 1"])
>     n2 -->|"binop-rhs"| n1
>     n6(["RFunctionCall (6)
> print"])
>     n7 -->|"expr-list-child-1"| n6
>     n3(["RSymbol (3)
> print"])
>     n6 -->|"call-name"| n3
>     n5(["RArgument (5)
> x"])
>     n6 -->|"call-argument-1"| n5
>     n4(["RSymbol (4)
> x"])
>     n5 -->|"arg-value"| n4
> 
> ```
> 	
> (The analysis required _5.46 ms_ (including parsing with the [tree-sitter](https://github.com/flowr-analysis/flowr/wiki/Engines) engine) within the generation environment.)
> 
> 
> 
> </details>
> 
> 
> 
> ```shell
> R> :dataflow* "x <- 1; print(x)"
> ```
> 
> <details>
> <summary style='color:gray'>Output</summary>
> 
> 
> ```text
> https://mermaid.live/view#base64:eyJjb2RlIjoiZmxvd2NoYXJ0IEJUXG4gICAgMXt7XCJgIzkxO1JOdW1iZXIjOTM7IDFcbiAgICAgICgxKVxuICAgICAgKjEuNipgXCJ9fVxuICAgIDBbXCJgIzkxO1JTeW1ib2wjOTM7IHhcbiAgICAgICgwKVxuICAgICAgKjEuMSpgXCJdXG4gICAgMltbXCJgIzkxO1JCaW5hcnlPcCM5MzsgIzYwOyM0NTtcbiAgICAgICgyKVxuICAgICAgKjEuMS02KlxuICAgICgwLCAxKWBcIl1dXG4gICAgNChbXCJgIzkxO1JTeW1ib2wjOTM7IHhcbiAgICAgICg0KVxuICAgICAgKjEuMTUqYFwiXSlcbiAgICA2W1tcImAjOTE7UkZ1bmN0aW9uQ2FsbCM5MzsgcHJpbnRcbiAgICAgICg2KVxuICAgICAgKjEuOS0xNipcbiAgICAoNClgXCJdXVxuICAgIDAgLS0+fFwiZGVmaW5lZC1ieVwifCAxXG4gICAgMCAtLT58XCJkZWZpbmVkLWJ5XCJ8IDJcbiAgICAyIC0tPnxcImFyZ3VtZW50XCJ8IDFcbiAgICAyIC0tPnxcInJldHVybnMsIGFyZ3VtZW50XCJ8IDBcbiAgICA0IC0tPnxcInJlYWRzXCJ8IDBcbiAgICA2IC0tPnxcInJlYWRzLCByZXR1cm5zLCBhcmd1bWVudFwifCA0IiwibWVybWFpZCI6eyJhdXRvU3luYyI6dHJ1ZX19
> ```
> 
> 
> Following the link output should show the following:
> 
> 
> 
> 
> ```mermaid
> flowchart LR
>     1{{"`#91;RNumber#93; 1
>       (1)
>       *1.6*`"}}
>     0["`#91;RSymbol#93; x
>       (0)
>       *1.1*`"]
>     2[["`#91;RBinaryOp#93; #60;#45;
>       (2)
>       *1.1-6*
>     (0, 1)`"]]
>     4(["`#91;RSymbol#93; x
>       (4)
>       *1.15*`"])
>     6[["`#91;RFunctionCall#93; print
>       (6)
>       *1.9-16*
>     (4)`"]]
>     0 -->|"defined-by"| 1
>     0 -->|"defined-by"| 2
>     2 -->|"argument"| 1
>     2 -->|"returns, argument"| 0
>     4 -->|"reads"| 0
>     6 -->|"reads, returns, argument"| 4
> ```
> 
> 	
> (The analysis required _1.12 ms_ (including parse and normalize, using the [tree-sitter](https://github.com/flowr-analysis/flowr/wiki/Engines) engine) within the generation environment.)
> 
> 
> 
> </details>
> 
> 
> 
> 
> </details>
>     


### Parsing

The parsing step uses the [<code><span title="The RShell represents an interactive session with the R interpreter. You can configure it by RShellOptions .  At the moment we are using a live R session (and not networking etc.) to communicate with R easily, which allows us to install packages etc. However, this might and probably will change in the future (leaving this as a legacy mode :D)">RShell</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/shell.ts#L140) to parse the input program (or, of course, the [<code><span title="Synchronous and (way) faster alternative to the RShell using tree-sitter.">TreeSitterExecutor</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/tree-sitter/tree-sitter-executor.ts#L16) when using the [`tree-sitter` engine](https://github.com/flowr-analysis/flowr/wiki/Engines)).
To speed up the process, we use the [<code><span title="Command(s) to be issued at the start of each shell">initCommand</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/init.ts#L6) function to compile the parsing function and rely on a 
custom serialization, which outputs the information in a CSV-like format.
This means, that the <span title="Description (Repl Command): Prints ASCII Art of the parsed, unmodified AST, start with 'file://' to indicate a file (aliases: :p)">`:parse`</span> command actually kind-of lies to you, as it does pretty print the serialized version which looks more like the following (this uses the [<code>retrieveParseDataFromRCode</code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/retriever.ts#L124) function with the sample code `x <- 1; print(x)`):


<details><summary style="">Raw parse output for <code>x <- 1; print(x)</code></summary>

For the code `x <- 1; print(x)`:


```csv
[1,1,1,6,7,0,"expr",false,"x <- 1"],[1,1,1,1,1,3,"SYMBOL",true,"x"],[1,1,1,1,3,7,"expr",false,"x"],[1,3,1,4,2,7,"LEFT_ASSIGN",true,"<-"],[1,6,1,6,4,5,"NUM_CONST",true,"1"],[1,6,1,6,5,7,"expr",false,"1"],[1,7,1,7,6,0,"';'",true,";"],[1,9,1,16,19,0,"expr",false,"print(x)"],[1,9,1,13,10,12,"SYMBOL_FUNCTION_CALL",true,"print"],[1,9,1,13,12,19,"expr",false,"print"],[1,14,1,14,11,19,"'('",true,"("],[1,15,1,15,13,15,"SYMBOL",true,"x"],[1,15,1,15,15,19,"expr",false,"x"],[1,16,1,16,14,19,"')'",true,")"]
```


</details>
    

Beautiful, right? I thought so too! In fact, the output is a little bit nicer, when we put it into a table-format and add the appropriate headers:

<details open>
<summary>Parse output in table format</summary>

For the code `x <- 1; print(x)`:

| line-start | col-start | line-end | col-end | id | parent | token type | terminal | text |
| ---------: | --------: | -------: | ------: | -: | -----: | ---------- | -------- | ---- |
| 1 | 1 | 1 | 6 | 7 | 0 | `expr` | false | x <- 1 |
| 1 | 1 | 1 | 1 | 1 | 3 | `SYMBOL` | true | x |
| 1 | 1 | 1 | 1 | 3 | 7 | `expr` | false | x |
| 1 | 3 | 1 | 4 | 2 | 7 | `LEFT_ASSIGN` | true | <- |
| 1 | 6 | 1 | 6 | 4 | 5 | `NUM_CONST` | true | 1 |
| 1 | 6 | 1 | 6 | 5 | 7 | `expr` | false | 1 |
| 1 | 7 | 1 | 7 | 6 | 0 | `';'` | true | ; |
| 1 | 9 | 1 | 16 | 19 | 0 | `expr` | false | print(x) |
| 1 | 9 | 1 | 13 | 10 | 12 | `SYMBOL_FUNCTION_CALL` | true | print |
| 1 | 9 | 1 | 13 | 12 | 19 | `expr` | false | print |
| 1 | 14 | 1 | 14 | 11 | 19 | `'('` | true | ( |
| 1 | 15 | 1 | 15 | 13 | 15 | `SYMBOL` | true | x |
| 1 | 15 | 1 | 15 | 15 | 19 | `expr` | false | x |
| 1 | 16 | 1 | 16 | 14 | 19 | `')'` | true | ) |

</details>

In fact, this data is merely what R's [`base::parse`](https://stat.ethz.ch/R-manual/R-devel/library/base/html/parse.html) and [`utils::getParseData`](https://stat.ethz.ch/R-manual/R-devel/library/utils/html/getParseData.html) functions provide.
We then use this data in the [normalization](#normalization) step to create a [normalized AST](https://github.com/flowr-analysis/flowr/wiki/Normalized-AST).

If you are interested in the raw token types that we may encounter, have a look at the [<code><span title="Token types as they are produced by the R parser. Not all of them are directly handled by the normalize step. Some of them are also listed as part of the OperatorDatabase .">RawRType</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/model/type.ts#L8) enum.

### Normalization

The normalization function [<code><span title="the normalized AST produced by the 'normalization' step, including its parent decoration">normalize</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/benchmark/slicer.ts#L65) takes the output from the previous steps and uses the [<code><span title="Takes the raw RShell output and extracts the csv information contained">prepareParsedData</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/parser/json/format.ts#L52) and 
[<code><span title="Takes the CSV-Entries and maps them to the old json format for compatibility.">convertPreparedParsedData</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/parser/json/format.ts#L87) functions to first transform the serialized parsing output to an object. 
Next, [<code><span title="Takes the parse dta as object and produces an undecorated, normalized AST.">normalizeRootObjToAst</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/parser/main/internal/structure/normalize-root.ts#L16) transforms this object to a normalized AST and [<code><span title="Covert the given AST into a doubly linked tree while assigning ids (so it stays serializable).">decorateAst</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/model/processing/decorate.ts#L150) adds additional information to the AST (like roles, ids, depth, etc.).
While looking at the mermaid visualization of such an AST is nice and usually sufficient, looking at the objects themselves shows you the full range of information the AST provides (all encompassed within the [<code><span title="The RNode type is the union of all possible nodes in the R-ast. It should be used whenever you either not care what kind of node you are dealing with or if you want to handle all possible nodes.    All other subtypes (like RLoopConstructs ) listed above can be used to restrict the kind of node. They do not have to be exclusive, some nodes can appear in multiple subtypes.">RNode</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/model/model.ts#L164) type).

Let's have a look at the normalized AST for the sample code `x <- 1; print(x)` (please refer to the [normalized AST](https://github.com/flowr-analysis/flowr/wiki/Normalized-AST) wiki page for more information):


<details><summary style="">Normalized AST for <code>x <- 1; print(x)</code></summary>


```json
{
    "type": "RExpressionList",
    "children": [
        {
            "type": "RBinaryOp",
            "location": [
                1,
                3,
                1,
                4
            ],
            "lhs": {
                "type": "RSymbol",
                "location": [
                    1,
                    1,
                    1,
                    1
                ],
                "content": "x",
                "lexeme": "x",
                "info": {
                    "fullRange": [
                        1,
                        1,
                        1,
                        1
                    ],
                    "additionalTokens": [],
                    "id": 0,
                    "parent": 2,
                    "role": "binop-lhs",
                    "index": 0,
                    "nesting": 0
                }
            },
            "rhs": {
                "location": [
                    1,
                    6,
                    1,
                    6
                ],
                "lexeme": "1",
                "info": {
                    "fullRange": [
                        1,
                        6,
                        1,
                        6
                    ],
                    "additionalTokens": [],
                    "id": 1,
                    "parent": 2,
                    "role": "binop-rhs",
                    "index": 1,
                    "nesting": 0
                },
                "type": "RNumber",
                "content": {
                    "num": 1,
                    "complexNumber": false,
                    "markedAsInt": false
                }
            },
            "operator": "<-",
            "lexeme": "<-",
            "info": {
                "fullRange": [
                    1,
                    1,
                    1,
                    6
                ],
                "additionalTokens": [],
                "id": 2,
                "parent": 7,
                "nesting": 0,
                "index": 0,
                "role": "expr-list-child"
            }
        },
        {
            "type": "RFunctionCall",
            "named": true,
            "location": [
                1,
                9,
                1,
                13
            ],
            "lexeme": "print",
            "functionName": {
                "type": "RSymbol",
                "location": [
                    1,
                    9,
                    1,
                    13
                ],
                "content": "print",
                "lexeme": "print",
                "info": {
                    "fullRange": [
                        1,
                        9,
                        1,
                        16
                    ],
                    "additionalTokens": [],
                    "id": 3,
                    "parent": 6,
                    "role": "call-name",
                    "index": 0,
                    "nesting": 0
                }
            },
            "arguments": [
                {
                    "type": "RArgument",
                    "location": [
                        1,
                        15,
                        1,
                        15
                    ],
                    "lexeme": "x",
                    "value": {
                        "type": "RSymbol",
                        "location": [
                            1,
                            15,
                            1,
                            15
                        ],
                        "content": "x",
                        "lexeme": "x",
                        "info": {
                            "fullRange": [
                                1,
                                15,
                                1,
                                15
                            ],
                            "additionalTokens": [],
                            "id": 4,
                            "parent": 5,
                            "role": "arg-value",
                            "index": 0,
                            "nesting": 0
                        }
                    },
                    "info": {
                        "fullRange": [
                            1,
                            15,
                            1,
                            15
                        ],
                        "additionalTokens": [],
                        "id": 5,
                        "parent": 6,
                        "nesting": 0,
                        "index": 1,
                        "role": "call-argument"
                    }
                }
            ],
            "info": {
                "fullRange": [
                    1,
                    9,
                    1,
                    16
                ],
                "additionalTokens": [],
                "id": 6,
                "parent": 7,
                "nesting": 0,
                "index": 1,
                "role": "expr-list-child"
            }
        }
    ],
    "info": {
        "additionalTokens": [],
        "id": 7,
        "nesting": 0,
        "role": "root",
        "index": 0
    }
}
```


</details>
    

This is… a lot! We get the type from the [<code><span title="Types as we use them for our normalized AST. See RNode for a union type of all normalized AST nodes in-use. For each enum member, the respective normalized AST node should be referenced in the corresponding comment.">RType</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/model/type.ts#L159) enum, the lexeme, location information, an id, the children of the node, and their parents.
While the [normalized AST](https://github.com/flowr-analysis/flowr/wiki/Normalized-AST) wiki page provides you with information on how to interpret this data, we will focus on how we get it from the
table provided by the [parsing](#parsing) step.

There are two important functions: [<code><span title="Takes the parse dta as object and produces an undecorated, normalized AST.">normalizeRootObjToAst</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/parser/main/internal/structure/normalize-root.ts#L16), which operates on the parse-output already transformed into a tree-like structure,
and [<code><span title="Covert the given AST into a doubly linked tree while assigning ids (so it stays serializable).">decorateAst</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/model/processing/decorate.ts#L150), which adds additional information to the AST.
Both follow a [fold](https://en.wikipedia.org/wiki/Fold_(higher-order_function)) pattern.
The fold is explicit for [<code><span title="Covert the given AST into a doubly linked tree while assigning ids (so it stays serializable).">decorateAst</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/model/processing/decorate.ts#L150), which directly relies on the [<code><span title="Folds in old functional-fashion over the AST structure but allowing for a down function which can pass context to child nodes.">foldAstStateful</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/model/processing/stateful-fold.ts#L79) function,
while [<code><span title="Takes the parse dta as object and produces an undecorated, normalized AST.">normalizeRootObjToAst</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/parser/main/internal/structure/normalize-root.ts#L16) uses the fold-idiom but deviates in cases in which (for example) we require more information on other nodes to know what it should be normalized too.

#### Normalizing the Object

We have a handler for everything. For example [<code><span title="Try to parse the construct as a RIfThenElse .">tryNormalizeIfThen</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/parser/main/internal/control/normalize-if-then.ts#L14) or [<code>tryNormalizeFor</code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/parser/main/internal/loops/normalize-for.ts#L18) to handle `if(x) y` or `for(i in 1:10) x` constructs.
All of these handlers contain many sanity checks to be sure that we talk to an [<code><span title="The RShell represents an interactive session with the R interpreter. You can configure it by RShellOptions .  At the moment we are using a live R session (and not networking etc.) to communicate with R easily, which allows us to install packages etc. However, this might and probably will change in the future (leaving this as a legacy mode :D)">RShell</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/shell.ts#L140) which we can handle (as assumptions may break with newer versions).
These functions contain the keyword `try` as they may fail. For example, whenever they notice late into normalization that they should actually be a different construct (R is great).
For single nodes, we use [<code><span title="Parses a single structure in the ast based on its type (e.g., a string, a number, a symbol, ...)">normalizeSingleNode</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/parser/main/internal/structure/normalize-single-node.ts#L27) which contains a catch-all for some edge-cases in the R grammar.

The output of just this pass is listed below (using the [<code><span title="Take the output as produced by the parse step and normalize the AST from the R parser. For additional decoration with $ decorateAst use normalize .">normalizeButNotDecorated</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/parser/json/parser.ts#L32) function):


<details><summary style="">Ast for <code>x <- 1; print(x)</code> after the first normalization</summary>


```json
{
    "type": "RExpressionList",
    "children": [
        {
            "type": "RBinaryOp",
            "location": [
                1,
                3,
                1,
                4
            ],
            "lhs": {
                "type": "RSymbol",
                "location": [
                    1,
                    1,
                    1,
                    1
                ],
                "content": "x",
                "lexeme": "x",
                "info": {
                    "fullRange": [
                        1,
                        1,
                        1,
                        1
                    ],
                    "additionalTokens": []
                }
            },
            "rhs": {
                "location": [
                    1,
                    6,
                    1,
                    6
                ],
                "lexeme": "1",
                "info": {
                    "fullRange": [
                        1,
                        6,
                        1,
                        6
                    ],
                    "additionalTokens": []
                },
                "type": "RNumber",
                "content": {
                    "num": 1,
                    "complexNumber": false,
                    "markedAsInt": false
                }
            },
            "operator": "<-",
            "lexeme": "<-",
            "info": {
                "fullRange": [
                    1,
                    1,
                    1,
                    6
                ],
                "additionalTokens": []
            }
        },
        {
            "type": "RFunctionCall",
            "named": true,
            "location": [
                1,
                9,
                1,
                13
            ],
            "lexeme": "print",
            "functionName": {
                "type": "RSymbol",
                "location": [
                    1,
                    9,
                    1,
                    13
                ],
                "content": "print",
                "lexeme": "print",
                "info": {
                    "fullRange": [
                        1,
                        9,
                        1,
                        16
                    ],
                    "additionalTokens": []
                }
            },
            "arguments": [
                {
                    "type": "RArgument",
                    "location": [
                        1,
                        15,
                        1,
                        15
                    ],
                    "lexeme": "x",
                    "value": {
                        "type": "RSymbol",
                        "location": [
                            1,
                            15,
                            1,
                            15
                        ],
                        "content": "x",
                        "lexeme": "x",
                        "info": {
                            "fullRange": [
                                1,
                                15,
                                1,
                                15
                            ],
                            "additionalTokens": []
                        }
                    },
                    "info": {
                        "fullRange": [
                            1,
                            15,
                            1,
                            15
                        ],
                        "additionalTokens": []
                    }
                }
            ],
            "info": {
                "fullRange": [
                    1,
                    9,
                    1,
                    16
                ],
                "additionalTokens": []
            }
        }
    ],
    "info": {
        "additionalTokens": []
    }
}
```


</details>
    


#### Decorating the AST

The decoration is comparatively trivial. We take the AST throw it into the [<code><span title="Covert the given AST into a doubly linked tree while assigning ids (so it stays serializable).">decorateAst</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/model/processing/decorate.ts#L150) function (which again, handles each normalized node type) and
get:

1. The AST with ids, roles, and depth information (see the [normalized AST](https://github.com/flowr-analysis/flowr/wiki/Normalized-AST) wiki page for more information).
2. A mapping of ids to nodes in the form of a [<code>AstIdMap</code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/model/processing/decorate.ts#L112) object. This allows us to quickly access nodes by their id.

The ids used for the AST generation are arbitrary (usually created by the [<code><span title="The simplest id generator which just increments a number on each call.">deterministicCountingIdGenerator</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/model/processing/decorate.ts#L41)) function) but unique and intentionally
separated from the ids used by the R&nbsp;parser. For one, this detaches us from the [Engine](https://github.com/flowr-analysis/flowr/wiki/Engines) used, and secondly, it allows for much easier
extension of the AST (e.g., when R&nbsp;files use [`base::source`](https://stat.ethz.ch/R-manual/R-devel/library/base/html/source.html) to include other R&nbsp;files).
All ids conform to the [<code><span title="The type of the id assigned to each node. Branded to avoid problematic usages with other string or numeric types.">NodeId</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/model/processing/node-id.ts#L7) type.

### Dataflow Graph Generation

The core of the dataflow graph generation works as a "stateful [fold](https://en.wikipedia.org/wiki/Fold_(higher-order_function))", 
which uses the tree-like structure of the AST to combine the dataflow information of the children, while tracking the currently active variables and control flow 
information as a “backpack” (state).	
We use the [<code><span title="This is the main function to produce the dataflow graph from a given request and normalized AST. Note, that this requires knowledge of the active parser in case the dataflow analysis uncovers other files that have to be parsed and integrated into the analysis (e.g., in the event of a source call). For the actual, canonical fold entry point, see processDataflowFor .">produceDataFlowGraph</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/extractor.ts#L94) function as an entry point to the dataflow generation (the actual fold entry is in [<code><span title="Originally, dataflow processor was written as a two-way fold, but this produced problems when trying to resolve function calls which require information regarding the calling *and* definition context. While this only is a problem for late bindings as they happen with functions (and probably quote'd R-expressions), it is still a problem that must be dealt with. Therefore, the dataflow processor has...">processDataflowFor</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/processor.ts#L70)).
The function is mainly backed by its [<code><span title="The best friend of produceDataFlowGraph and processDataflowFor . Maps every RType in the normalized AST to a processor.">processors</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/extractor.ts#L35) object which maps each type in the normalized AST to an appropriate handler ("fold-function").

To understand these handlers, let's start with the simplest one, [<code>processUninterestingLeaf</code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/internal/process/process-uninteresting-leaf.ts#L5) signals that 
we do not care about this node and just produce an empty dataflow information (using [<code><span title="Initializes an empty DataflowInformation object with the given entry point and data. This is to be used as a 'starting point' when processing leaf nodes during the dataflow extraction.">initializeCleanDataflowInformation</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/info.ts#L123)). 
Looking at the function showcases the general structure of a processor:

 * [processUninterestingLeaf](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/internal/process/process-uninteresting-leaf.ts#L5)   
 
   <details open><summary style="color:gray">Defined at <a href="https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/internal/process/process-uninteresting-leaf.ts#L5">./src/dataflow/internal/process/process-uninteresting-leaf.ts#L5</a></summary>
   
   
   ```ts
   export function processUninterestingLeaf<OtherInfo>(leaf: RNodeWithParent, info: DataflowProcessorInformation<OtherInfo>): DataflowInformation {
       return initializeCleanDataflowInformation(leaf.info.id, info);
   }
   ```
   
   
   </details>
   

Every processor has the same shape. It takes the normalized node (see the [normalized AST](https://github.com/flowr-analysis/flowr/wiki/Normalized-AST) for more information),
and a [<code>DataflowProcessorInformation</code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/processor.ts#L15) object which, as some kind of "backpack" carries global information
to every handler. 
This information is to be used to create a [<code><span title="The dataflow information is one of the fundamental structures we have in the dataflow analysis. It is continuously updated during the dataflow analysis and holds its current state for the respective subtree processed. Each processor during the dataflow analysis may use the information from its children to produce a new state of the dataflow information.  You may initialize a new dataflow informati...">DataflowInformation</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/info.ts#L89):

 * **[DataflowInformation](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/info.ts#L89)**   
   The dataflow information is one of the fundamental structures we have in the dataflow analysis.
   It is continuously updated during the dataflow analysis
   and holds its current state for the respective subtree processed.
   Each processor during the dataflow analysis may use the information from its children
   to produce a new state of the dataflow information.
    You may initialize a new dataflow information with
   <code>initializeCleanDataflowInformation</code>
   .
   <details><summary style="color:gray">Defined at <a href="https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/info.ts#L89">./src/dataflow/info.ts#L89</a></summary>
   
   
   ```ts
   /**
    * The dataflow information is one of the fundamental structures we have in the dataflow analysis.
    * It is continuously updated during the dataflow analysis
    * and holds its current state for the respective subtree processed.
    * Each processor during the dataflow analysis may use the information from its children
    * to produce a new state of the dataflow information.
    *
    * You may initialize a new dataflow information with {@link initializeCleanDataflowInformation}.
    *
    * @see {@link DataflowCfgInformation} - the control flow aspects
    */
   export interface DataflowInformation extends DataflowCfgInformation {
       /**
        * References that have not been identified as read or write and will be so on higher processors.
        *
        * For example, when we analyze the `x` vertex in `x <- 3`, we will first create an unknown reference for `x`
        * as we have not yet seen the assignment!
        *
        * @see {@link IdentifierReference} - a reference on a variable, parameter, function call, ...
        */
       unknownReferences: readonly IdentifierReference[]
       /**
        * References which are read within the current subtree.
        *
        * @see {@link IdentifierReference} - a reference on a variable, parameter, function call, ...
        * */
       in:                readonly IdentifierReference[]
       /**
        * References which are written to within the current subtree
        *
        * @see {@link IdentifierReference} - a reference on a variable, parameter, function call, ...
        */
       out:               readonly IdentifierReference[]
       /** Current environments used for name resolution, probably updated on the next expression-list processing */
       environment:       REnvironmentInformation
       /** The current constructed dataflow graph */
       graph:             DataflowGraph
   }
   ```
   
   
   </details>
   
    <details><summary style="">View more (DataflowCfgInformation)</summary>

   * **[DataflowCfgInformation](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/info.ts#L71)**   
     The control flow information for the current DataflowInformation.
     <details><summary style="color:gray">Defined at <a href="https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/info.ts#L71">./src/dataflow/info.ts#L71</a></summary>
     
     
     ```ts
     /** The control flow information for the current DataflowInformation. */
     export interface DataflowCfgInformation {
         /** The entry node into the subgraph */
         entryPoint: NodeId,
         /** All already identified exit points (active 'return'/'break'/'next'-likes) of the respective structure. */
         exitPoints: readonly ExitPoint[]
     }
     ```
     
     
     </details>
     

</details>
    

Essentially, these processors should use the dataflow information from their children combined with their own semantics
to produce a new dataflow information to pass upwards in the fold. The [<code><span title="The dataflow information is one of the fundamental structures we have in the dataflow analysis. It is continuously updated during the dataflow analysis and holds its current state for the respective subtree processed. Each processor during the dataflow analysis may use the information from its children to produce a new state of the dataflow information.  You may initialize a new dataflow informati...">DataflowInformation</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/info.ts#L89) contains:

* the [<code><span title="The dataflow graph holds the dataflow information found within the given AST. We differentiate the directed edges in EdgeType and the vertices indicated by DataflowGraphVertexArgument The vertices of the graph are organized in a hierarchical fashion, with a function-definition node containing the node ids of its subgraph. However, all *edges* are hoisted at the top level in the form of an (attribu...">DataflowGraph</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/graph/graph.ts#L139) of the current subtree 
* the currently active [<code><span title="An environment describes a ( scoped ) mapping of names to their definitions ( EnvironmentMemory ).  First, yes, R stores its environments differently, potentially even with another differentiation between the baseenv, the emptyenv, and other default environments (see https://adv-r.hadley.nz/environments.html). Yet, during the dataflow analysis, we want sometimes to know more (static reference info...">REnvironmentInformation</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/environments/environment.ts#L103) as an abstraction of all active definitions linking to potential definition locations (see [Advanced R::Environments](https://adv-r.hadley.nz/environments.html))
* control flow information in [<code><span title="The control flow information for the current DataflowInformation.">DataflowCfgInformation</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/info.ts#L71) which is used to enrich the dataflow information with control flow information
* and sets of currently ingoing (read), outgoing (write) and unknown [<code><span title="An identifier reference points to a variable like a in b <- a. Without any surrounding code, a will produce the identifier reference a. Similarly, b will create a reference (although it will be an identifier definition which adds even more information).  In general, references are merely pointers (with meta-information) to a vertex in the dataflow graph . In the context of the extractor, for examp...">IdentifierReference</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/environments/identifier.ts#L73)s.

While all of them are essentially empty when processing an “uninteresting leaf”, handling a constant is slightly more interesting with [<code>processValue</code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/internal/process/process-value.ts#L8):

 * [processValue](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/internal/process/process-value.ts#L8)   
 
   <details open><summary style="color:gray">Defined at <a href="https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/internal/process/process-value.ts#L8">./src/dataflow/internal/process/process-value.ts#L8</a></summary>
   
   
   ```ts
   export function processValue<OtherInfo>({ info: { id } }: RNodeWithParent, data: DataflowProcessorInformation<OtherInfo>): DataflowInformation {
       return {
           unknownReferences: [],
           in:                [{ nodeId: id, name: undefined, controlDependencies: data.controlDependencies, type: ReferenceType.Constant }],
           out:               [],
           environment:       data.environment,
           graph:             new DataflowGraph(data.completeAst.idMap).addVertex({
               tag: VertexType.Value,
               id:  id,
               cds: data.controlDependencies
           }),
           exitPoints: [{ nodeId: id, type: ExitPointType.Default, controlDependencies: data.controlDependencies }],
           entryPoint: id
       };
   }
   ```
   
   
   </details>
   

Please note, that we add the [value vertex](https://github.com/flowr-analysis/flowr/wiki/Dataflow-Graph#value-vertex) to the newly created dataflow graph,
which holds a reference to the constant. If you are confused with the use of the [<code>ParentInformation</code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/model/processing/decorate.ts#L102) type, 
this stems from the [AST decoration](#normalization) and signals that we have a decorated [<code><span title="The RNode type is the union of all possible nodes in the R-ast. It should be used whenever you either not care what kind of node you are dealing with or if you want to handle all possible nodes.    All other subtypes (like RLoopConstructs ) listed above can be used to restrict the kind of node. They do not have to be exclusive, some nodes can appear in multiple subtypes.">RNode</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/model/model.ts#L164) (which may have additional information in `OtherInfo`).

Yet again, this is not very interesting. When looking at the [<code><span title="The best friend of produceDataFlowGraph and processDataflowFor . Maps every RType in the normalized AST to a processor.">processors</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/extractor.ts#L35) object you may be confused by
many lines just mapping the node to the [<code><span title="Helper function for processNamedCall using the given functionName as the name of the function.">processAsNamedCall</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/internal/process/process-named-call.ts#L13) function.
This is because during the dataflow analysis we actually "desugar" the AST, and treat syntax constructs like binary operators (e.g., `x + y`) as function calls (e.g. `` `+`(x, y) ``).
We do this, because R does it the same way, and allows to even overwrite these operators (including `if`, `<-`, etc.) by their name.
By treating them like R, as function calls, we get support for these overwrites for free, courtesy of flowR's call resolution.

But where are all the interesting things handled then? 
For that, we want to have a look at the built-in environment, which can be freely configured using flowR's [configuration system](https://github.com/flowr-analysis/flowr/wiki/Interface#configuring-flowr).
FlowR's heart and soul resides in the [<code><span title="Contains the built-in definitions recognized by flowR">DefaultBuiltinConfig</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/environments/default-builtin-config.ts#L101) object, which is used to configure the built-in environment
by mapping function names to [<code>BuiltInProcessorMapper</code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/environments/built-in.ts#L169) functions.
There you can find functions like [<code><span title="Processes different types of access operations.  Example:   a[i] a$foo a[[i]] a@foo  ">processAccess</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/internal/process/functions/call/built-in/built-in-access.ts#L50) which handles the (subset) access to a variable, 
or [<code>processForLoop</code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/internal/process/functions/call/built-in/built-in-for-loop.ts#L22) which handles the primitive for loop construct (whenever it is not overwritten).

Just as an example, we want to have a look at the [<code>processRepeatLoop</code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/internal/process/functions/call/built-in/built-in-repeat-loop.ts#L19) function, as it is one of the simplest built-in processors
we have:

 * [processRepeatLoop](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/internal/process/functions/call/built-in/built-in-repeat-loop.ts#L19)   
 
   <details open><summary style="color:gray">Defined at <a href="https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/internal/process/functions/call/built-in/built-in-repeat-loop.ts#L19">./src/dataflow/internal/process/functions/call/built-in/built-in-repeat-loop.ts#L19</a></summary>
   
   
   ```ts
   export function processRepeatLoop<OtherInfo>(
       name: RSymbol<OtherInfo & ParentInformation>,
       args: readonly RFunctionArgument<OtherInfo & ParentInformation>[],
       rootId: NodeId,
       data: DataflowProcessorInformation<OtherInfo & ParentInformation>
   ): DataflowInformation {
       if(args.length !== 1 || args[0] === EmptyArgument) {
           dataflowLogger.warn(`Repeat-Loop ${name.content} does not have 1 argument, skipping`);
           return processKnownFunctionCall({ name, args, rootId, data }).information;
       }
   
       const unpacked = unpackArgument(args[0]);
       const { information, processedArguments } = processKnownFunctionCall({
           name,
           args:      unpacked ? [unpacked] : args,
           rootId,
           data,
           patchData: (d, i) => {
               if(i === 0) {
                   return { ...d, controlDependencies: [...d.controlDependencies ?? [], { id: name.info.id }] };
               }
               return d;
           },
           markAsNSE: [0]
       });
   
       const body = processedArguments[0];
       guard(body !== undefined, () => `Repeat-Loop ${name.content} has no body, impossible!`);
   
       linkCircularRedefinitionsWithinALoop(information.graph, produceNameSharedIdMap(findNonLocalReads(information.graph, [])), body.out);
   
       information.exitPoints = filterOutLoopExitPoints(information.exitPoints);
   
       return information;
   }
   ```
   
   
   </details>
   

Similar to any other built-in processor, we get the name of the function call which caused us to land here,
as well as the passed arguments. The `rootId` refers to what caused the call to happen (and is usually just the function call),
while `data` is our good old backpack, carrying all the information we need to produce a dataflow graph.

After a couple of common sanity checks at the beginning which we use to check whether the repeat loop is used in a way that we expect,
we start by issuing the fold continuation by processing its arguments. Given we expect `repeat <body>`, we expect only a single argument.
During the processing we make sure to stitch in the correct control dependencies, adding the repeat loop to the mix.
For just the repeat loop the stitching is actually not necessary, but this way the handling is consistent for all looping constructs.

Afterward, we take the `processedArguments`, perform another round of sanity checks and then use two special functions to apply the
semantic effects of the repeat loop. We first use one of flowR's linkers to
[<code><span title="all loops variables which are open read (not already bound by a redefinition within the loop) get a maybe read marker to their last definition within the loop e.g. with:   for(i in 1:10) { x_1 <- x_2 + 1 }   x_2 must get a read marker to x_1 as x_1 is the active redefinition in the second loop iteration.">linkCircularRedefinitionsWithinALoop</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/internal/linker.ts#L368) and then retrieve the active exit points with [<code><span title="Filters out exit points which end their cascade within a loop.">filterOutLoopExitPoints</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/dataflow/info.ts#L175).

Feel free to have a look around and explore the other handlers for now. Each of them uses the results of its children alongside the active backpack 
to produce a new dataflow information.

## Beyond the Dataflow Graph

Given the [dataflow graph](https://github.com/flowr-analysis/flowr/wiki/Dataflow-Graph), you can do a lot more!
You can issue [queries](https://github.com/flowr-analysis/flowr/wiki/Query-API) to explore the graph, [search](https://github.com/flowr-analysis/flowr/wiki/Search-API) for specific elements, or, for example, request a [static backward slice](#static-backward-slicing).
Of course, all of these endeavors work not just with the [<code><span title="The RShell represents an interactive session with the R interpreter. You can configure it by RShellOptions .  At the moment we are using a live R session (and not networking etc.) to communicate with R easily, which allows us to install packages etc. However, this might and probably will change in the future (leaving this as a legacy mode :D)">RShell</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/shell.ts#L140) but also with the [`tree-sitter` engine](https://github.com/flowr-analysis/flowr/wiki/Engines). 

### Static Backward Slicing

The slicing is available as an extra step as you can see by inspecting he [<code>DEFAULT_SLICING_PIPELINE</code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/pipeline/default-pipelines.ts#L18).
Besides [<code>STATIC_SLICE</code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/all/static-slicing/00-slice.ts#L21) it contains a [<code>NAIVE_RECONSTRUCT</code>](https://github.com/flowr-analysis/flowr/tree/main//src/core/steps/all/static-slicing/10-reconstruct.ts#L18) to print the slice as (executable) R code.

Your main point of interesting here is the [<code><span title="This returns the ids to include in the static backward slice, when slicing with the given seed id's (must be at least one).   The returned ids can be used to reconstruct the slice to R code .">staticSlicing</span></code>](https://github.com/flowr-analysis/flowr/tree/main//src/slicing/static/static-slicer.ts#L32) function which relies on a modified
breadth-first search to collect all nodes which are part of the slice. 
For more information on how the slicing works, please refer to the [tool demonstration (Section 3.2)](https://doi.org/10.1145/3691620.3695359),
or the [original master's thesis (Chapter 4)](https://doi.org/10.18725/OPARU-50107).

You can explore the slicing using the REPL with the <span title="Description (Repl Command): Static backwards executable slicer for R">`:slicer`</span> command:



```shell
$ docker run -it --rm eagleoutice/flowr # or npm run flowr 
flowR repl using flowR v2.2.12, R v4.4.3 (r-shell engine)
R> :slicer test/testfiles/example.R --criterion "12@product"
```

<details open>
<summary style='color:gray'>Output</summary>


```text
product <- 1
N <- 10
for(i in 1:(N-1)) product <- product * i
product
```


Slice for the example file for the variable "prod" in line 12.

</details>



## Helpful Things

### Getting flowR to Talk

When using flowR from the CLI, you can use the <span title="Description (Command Line Argument): Run with verbose logging (will be passed to the corresponding script)">`--verbose`</span> option to get more information about what flowR is doing.
While coding, however, you can use the  function to set the minimum level of logs to be displayed (this works with the [<code>FlowrLogger</code>](https://github.com/flowr-analysis/flowr/tree/main//src/util/log.ts#L10) abstraction).
In general, you can configure the levels of individual logs, such as the general `log` (obtained with [<code>getActiveLog</code>](https://github.com/flowr-analysis/flowr/tree/main//src/util/log.ts#L61)) or the [<code>parseLog</code>](https://github.com/flowr-analysis/flowr/tree/main//src/r-bridge/lang-4.x/ast/parser/json/parser.ts#L12).
Please note that flowR makes no guarantees that log outputs are persistent across versions, and it is up to the implementors to provide sensible logging.
If you are an implementor and want to add logging, please make sure there are no larger runtime impliciations when logging is disabled. 
Have a look at the [<code>expensiveTrace</code>](https://github.com/flowr-analysis/flowr/tree/main//src/util/log.ts#L4) function for example, which uses a function to generate the log message only when the log level is reached.


